X1_avg <- mean(X1)
X2_avg <- mean(X2)
X3_avg <- mean(X3)
T1 <- soil_moisture$T1
T2 <- soil_moisture$T2
T3 <- soil_moisture$T3
T1_avg <- mean(T1)
T2_avg <- mean(T2)
T3_avg <- mean(T3)
soil_moisture$ubrmse_1 <- ((X1 - X1_avg) - (T1 - T1_avg))^2
soil_moisture$ubrmse_2 <- ((X2 - X2_avg) - (T2 - T2_avg))^2
soil_moisture$ubrmse_3 <- ((X3 - X3_avg) - (T3 - T3_avg))^2
print(paste("The unbiased RMSE for dataset 1 is", round(sqrt(mean(soil_moisture$ubrmse_1)), 3),"This is expected given that it is the reference dataset."))
print(paste("The unbiased RMSE for dataset 2 is", round(sqrt(mean(soil_moisture$ubrmse_2)), 3)))
print(paste("The unbiased RMSE for dataset 3 is", round(sqrt(mean(soil_moisture$ubrmse_3)), 3)))
soil_moisture$T1 <- (X1 - a1) / B1
soil_moisture$T2 <- (X2 - a2) / B2
soil_moisture$T3 <- (X3 - a3) / B3
X1_avg <- mean(X1)
X2_avg <- mean(X2)
X3_avg <- mean(X3)
T1 <- soil_moisture$T1
T2 <- soil_moisture$T2
T3 <- soil_moisture$T3
T1_avg <- mean(T1)
T2_avg <- mean(T2)
T3_avg <- mean(T3)
soil_moisture$ubrmse_1 <- ((X1 - X1_avg) - (T1 - T1_avg))^2
soil_moisture$ubrmse_2 <- ((X2 - X2_avg) - (T2 - T2_avg))^2
soil_moisture$ubrmse_3 <- ((X3 - X3_avg) - (T3 - T3_avg))^2
print(paste("The unbiased RMSE for dataset 1 is", round(sqrt(mean(soil_moisture$ubrmse_1)), 3),". This is expected given that it is the reference dataset."))
print(paste("The unbiased RMSE for dataset 2 is", round(sqrt(mean(soil_moisture$ubrmse_2)), 3)))
print(paste("The unbiased RMSE for dataset 3 is", round(sqrt(mean(soil_moisture$ubrmse_3)), 3)))
#get the random errors
e1 <- sqrt(cov(X1, X1) - ((cov(X1, X2)*cov(X1, X3))/(cov(X2, X3))))
e2 <- sqrt(cov(X2, X2) - ((cov(X1, X2)*cov(X2, X3))/(cov(X1, X3))))
e1 <- sqrt(cov(X3, X3) - ((cov(X1, X3)*cov(X2, X3))/(cov(X1, X2))))
# calculate our "True" value based off of equation where Xi(t) = a_i + BiT(t) + e_i(t)
soil_moisture$T1 <- (X1 - a1 - e1) / B1
soil_moisture$T2 <- (X2 - a2 - e2) / B2
soil_moisture$T3 <- (X3 - a3 - e3) / B3
#get the random errors
e1 <- sqrt(cov(X1, X1) - ((cov(X1, X2)*cov(X1, X3))/(cov(X2, X3))))
e2 <- sqrt(cov(X2, X2) - ((cov(X1, X2)*cov(X2, X3))/(cov(X1, X3))))
e3 <- sqrt(cov(X3, X3) - ((cov(X1, X3)*cov(X2, X3))/(cov(X1, X2))))
# calculate our "True" value based off of equation where Xi(t) = a_i + BiT(t) + e_i(t)
soil_moisture$T1 <- (X1 - a1 - e1) / B1
soil_moisture$T2 <- (X2 - a2 - e2) / B2
soil_moisture$T3 <- (X3 - a3 - e3) / B3
X1_avg <- mean(X1)
X2_avg <- mean(X2)
X3_avg <- mean(X3)
T1 <- soil_moisture$T1
T2 <- soil_moisture$T2
T3 <- soil_moisture$T3
T1_avg <- mean(T1)
T2_avg <- mean(T2)
T3_avg <- mean(T3)
soil_moisture$ubrmse_1 <- ((X1 - X1_avg) - (T1 - T1_avg))^2
soil_moisture$ubrmse_2 <- ((X2 - X2_avg) - (T2 - T2_avg))^2
soil_moisture$ubrmse_3 <- ((X3 - X3_avg) - (T3 - T3_avg))^2
print(paste("The unbiased RMSE for dataset 1 is", round(sqrt(mean(soil_moisture$ubrmse_1)), 3),". This is expected given that it is the reference dataset."))
print(paste("The unbiased RMSE for dataset 2 is", round(sqrt(mean(soil_moisture$ubrmse_2)), 3)))
print(paste("The unbiased RMSE for dataset 3 is", round(sqrt(mean(soil_moisture$ubrmse_3)), 3)))
e2
e3
P1 <- sqrt((cov(X1,X2)*cov(X, X3))/(cov(X1,X1)*cov(X2,X3)))
P1 <- sqrt((cov(X1,X2)*cov(X1, X3))/(cov(X1,X1)*cov(X2,X3)))
P1
P1 <- sqrt((cov(X1,X2)*cov(X1, X3))/(cov(X1,X1)*cov(X2,X3)))
P2_pos <- (cov(X1, X3)*cov(X2, X3))*(sqrt((cov(X1,X2)*cov(X2, X3))/(cov(X2,X2)*cov(X1,X3))))
P2_neg <- -(cov(X1, X3)*cov(X2, X3))*(sqrt((cov(X1,X2)*cov(X2, X3))/(cov(X2,X2)*cov(X1,X3))))
P2_neg
P2_pos
P1 <- sqrt((cov(X1,X2)*cov(X1, X3))/(cov(X1,X1)*cov(X2,X3)))
P2_pos <- (cov(X1, X3)*cov(X2, X3))*(sqrt((cov(X1,X2)*cov(X2, X3))/(cov(X2,X2)*cov(X1,X3))))
P2_neg <- -(cov(X1, X3)*cov(X2, X3))*(sqrt((cov(X1,X2)*cov(X2, X3))/(cov(X2,X2)*cov(X1,X3))))
P3_pos <- (cov(X1, X2)*cov(X2, X3))*(sqrt((cov(X1,X3)*cov(X2, X3))/(cov(X3,X3)*cov(X1,X2))))
P3_neg <- -(cov(X1, X2)*cov(X2, X3))*(sqrt((cov(X1,X3)*cov(X2, X3))/(cov(X3,X3)*cov(X1,X2))))
P3_neg
P3_pos
soil_moisture <- read.csv("Q2_soil_moisture.csv")
a1 <- 0
B1 <- 1
X1 <- soil_moisture$X1
X2 <- soil_moisture$X2
X3 <- soil_moisture$X3
B2 <- (cov(X2, X3))/(cov(X1, X3))
B3 <- (cov(X2, X3))/(cov(X1, X2))
a2 <- mean(X2) - (B2 * mean(X1))
a3 <- mean(X3) - (B3 * mean(X1))
#get the random errors
e1 <- sqrt(cov(X1, X1) - ((cov(X1, X2)*cov(X1, X3))/(cov(X2, X3))))
e2 <- sqrt(cov(X2, X2) - ((cov(X1, X2)*cov(X2, X3))/(cov(X1, X3))))
e3 <- sqrt(cov(X3, X3) - ((cov(X1, X3)*cov(X2, X3))/(cov(X1, X2))))
# calculate our "True" value based off of equation where Xi(t) = a_i + BiT(t) + e_i(t)
soil_moisture$T1 <- (X1 - a1 - e1) / B1
soil_moisture$T2 <- (X2 - a2 - e2) / B2
soil_moisture$T3 <- (X3 - a3 - e3) / B3
X1_avg <- mean(X1)
X2_avg <- mean(X2)
X3_avg <- mean(X3)
T1 <- soil_moisture$T1
T2 <- soil_moisture$T2
T3 <- soil_moisture$T3
T1_avg <- mean(T1)
T2_avg <- mean(T2)
T3_avg <- mean(T3)
soil_moisture$ubrmse_1 <- ((X1 - X1_avg) - (T1 - T1_avg))^2
soil_moisture$ubrmse_2 <- ((X2 - X2_avg) - (T2 - T2_avg))^2
soil_moisture$ubrmse_3 <- ((X3 - X3_avg) - (T3 - T3_avg))^2
soil_moisture <- read.csv("Q2_soil_moisture.csv")
a1 <- 0
B1 <- 1
X1 <- soil_moisture$X1
X2 <- soil_moisture$X2
X3 <- soil_moisture$X3
B2 <- (cov(X2, X3))/(cov(X1, X3))
B3 <- (cov(X2, X3))/(cov(X1, X2))
a2 <- mean(X2) - (B2 * mean(X1))
a3 <- mean(X3) - (B3 * mean(X1))
P2
P1 <- sqrt((cov(X1,X2)*cov(X1, X3))/(cov(X1,X1)*cov(X2,X3)))
P2 <- (cov(X1, X3)*cov(X2, X3))*(sqrt((cov(X1,X2)*cov(X2, X3))/(cov(X2,X2)*cov(X1,X3))))
P3 <- (cov(X1, X2)*cov(X2, X3))*(sqrt((cov(X1,X3)*cov(X2, X3))/(cov(X3,X3)*cov(X1,X2))))
p2
P2
(cov(X1, X3)*cov(X2, X3))
cov(X1, X3)
X3
head(soil_moisture)
cov(soil_moisture$X1, soil_moisture$X3)
cov(X1, X3)
mean(x1)
meanX1
mean(X1)
mean(X2)
mean(X3)
(sqrt((cov(X1,X2)*cov(X2, X3))/(cov(X2,X2)*cov(X1,X3)))
)
(sqrt((cov(X1,X3)*cov(X2, X3))/(cov(X3,X3)*cov(X1,X2)))
)
P1
P2
P3
(sqrt((cov(X1,X2)*cov(X2, X3))/(cov(X2,X2)*cov(X1,X3))))
sqrt((cov(X1,X2)*cov(X1, X3))/(cov(X1,X1)*cov(X2,X3)))
(sqrt((cov(X1,X3)*cov(X2, X3))/(cov(X3,X3)*cov(X1,X2))))
(cov(X1, X3)*cov(X2, X3))
P1 <- sqrt((cov(X1,X2)*cov(X1, X3))/(cov(X1,X1)*cov(X2,X3)))
P2 <- -(cov(X1, X3)*cov(X2, X3))*(sqrt((cov(X1,X2)*cov(X2, X3))/(cov(X2,X2)*cov(X1,X3))))
P3 <- (cov(X1, X2)*cov(X2, X3))*(sqrt((cov(X1,X3)*cov(X2, X3))/(cov(X3,X3)*cov(X1,X2))))
P2
P1 <- sqrt((cov(X1,X2)*cov(X1, X3))/(cov(X1,X1)*cov(X2,X3)))
P2 <- (-1 *(cov(X1, X3)*cov(X2, X3)))*(sqrt((cov(X1,X2)*cov(X2, X3))/(cov(X2,X2)*cov(X1,X3))))
P3 <- (cov(X1, X2)*cov(X2, X3))*(sqrt((cov(X1,X3)*cov(X2, X3))/(cov(X3,X3)*cov(X1,X2))))
P2
sign(56)
sign(-56)
sign(-564247329)
P1 <- sqrt((cov(X1,X2)*cov(X1, X3))/(cov(X1,X1)*cov(X2,X3)))
P2 <- sign(cov(X1, X3)*cov(X2, X3))*(sqrt((cov(X1,X2)*cov(X2, X3))/(cov(X2,X2)*cov(X1,X3))))
P3 <- sign(cov(X1, X2)*cov(X2, X3))*(sqrt((cov(X1,X3)*cov(X2, X3))/(cov(X3,X3)*cov(X1,X2))))
P2
P3
$ \epsilon ' $ as you move from Sandy loam to silty clay, $ \epsilon ' $ gets smaller for the same level of moisture, while $ \epsilon " $
-- a much smaller component--is pretty similar across the different
$ \epsilon " $
```{r, echo=TRUE}
exp(-tau/cos(theta))
tau <- .3
exp(-tau/cos(theta))
knitr::opts_chunk$set(echo = TRUE)
#Convert theta 35 degrees to radians
deg2rad <- function(deg) {(deg * pi) / (180)}
theta <- deg2rad(35)
w <- 0.05
Temp <- 20
h <- 0.13
tau <- 0.3
e <- 4
r_h_top <- cos(theta) - sqrt(e - (sin(theta)^2))
r_h_bottom <- cos(theta) + sqrt(e - (sin(theta)^2))
r_h <- abs(r_h_top/r_h_bottom)^2
r_h_rough <- r_h*exp(-h * cos(theta))
T_b_h = exp(-tau/cos(theta))
exp(-tau/cos(theta))
exp(-tau/(cos(theta))
)
#Convert theta 35 degrees to radians
deg2rad <- function(deg) {(deg * pi) / (180)}
theta <- deg2rad(35)
w <- 0.05
Temp <- 20
h <- 0.13
tau <- 0.3
e <- 4
r_h_top <- cos(theta) - sqrt(e - (sin(theta)^2))
r_h_bottom <- cos(theta) + sqrt(e - (sin(theta)^2))
r_h <- abs(r_h_top/r_h_bottom)^2
r_h_rough <- r_h*exp(-h * cos(theta))
T_b_h = (exp(-tau/cos(theta)) * (1 - r_h_rough) * T) + ((1-w) * (1 - exp(-tau/cos(theta))) * (1 + (r_h_rough*exp(-tau/cos(theta)))) * T)
T_b_h
r_h_rough
r_h
theta
?cos
theta
cos(theta)
sqrt(e - (sin(theta)^2)
)
r_h_top
r_h_n
r_h_b
r_h_bottom
abs(r_h_top/r_h_bottom)
.4^2
r_h_rough
ex <- exp(-tau/cos(theta))
(ex * (1 - r_h_rough) * T)
ex
tau
cos(theta)
-tau/cos(theta)
exp(-.366)
T_b_h = ex * (1 - r_h_rough) * T + (1-w) * (1 - ex) * (1 + (r_h_rough*ex)) * T
T_b_h
r_h_rough*ex
r_h_rough*ex+1
#Convert theta 35 degrees to radians
deg2rad <- function(deg) {(deg * pi) / (180)}
theta <- deg2rad(35)
w <- 0.05
Temp <- 20
h <- 0.13
tau <- 0.3
e <- 4
r_h_top <- cos(theta) - sqrt(e - (sin(theta)^2))
r_h_bottom <- cos(theta) + sqrt(e - (sin(theta)^2))
r_h <- abs(r_h_top/r_h_bottom)^2
r_h_rough <- r_h*exp(-h * cos(theta))
ex <- exp(-tau/cos(theta))
T_b_h = (ex * (1 - r_h_rough) * Temp) + (1-w) * (1 - ex) * (1 + (r_h_rough*ex)) * Temp
T_b_h
#Convert theta 35 degrees to radians
deg2rad <- function(deg) {(deg * pi) / (180)}
theta <- deg2rad(35)
w <- 0.05
Temp <- 293.15 #this is from 20 celcius to kelvin
h <- 0.13
tau <- 0.3
e <- 4
r_h_top <- cos(theta) - sqrt(e - (sin(theta)^2))
r_h_bottom <- cos(theta) + sqrt(e - (sin(theta)^2))
r_h <- abs(r_h_top/r_h_bottom)^2
r_h_rough <- r_h*exp(-h * cos(theta))
ex <- exp(-tau/cos(theta))
T_b_h = (ex * (1 - r_h_rough) * Temp) + (1-w) * (1 - ex) * (1 + (r_h_rough*ex)) * Temp
T_b_h
#Convert theta 35 degrees to radians
deg2rad <- function(deg) {(deg * pi) / (180)}
theta <- deg2rad(35)
w <- 0.05
Temp <- 293.15 #this is from 20 celcius to kelvin
h <- 0.13
tau <- 0.3
e <- 4
r_h_top <- cos(theta) - sqrt(e - (sin(theta)^2))
r_h_bottom <- cos(theta) + sqrt(e - (sin(theta)^2))
r_h <- abs(r_h_top/r_h_bottom)^2
r_h_rough <- r_h*exp(-h * cos(theta))
ex <- exp(-tau/cos(theta))
T_b_h = (ex * (1 - r_h_rough) * Temp) + (1-w) * (1 - ex) * (1 + (r_h_rough*ex)) * Temp
T_b_h
ex
ex
ex*Temp
1-w
(1-w)*(1-ex)*Temp
1-.28
timestamp()
##------ Mon Aug 10 14:47:09 2020 ------##
ifelse(dir.exists("~/Box Sync/heatwave_covid"),
setwd("~/Box Sync/heatwave_covid"),
setwd("/oak/stanford/groups/omramom/group_members/aminaly/heatwave_covid"))
source("./regression_functions.R")
library(dplyr)
library(lfe)
library(ggplot2)
library(dotwhisker)
library(tidyverse)
library(lubridate)
library(reshape2)
##Read in datasets
t <- read_rds(paste0(getwd(), "/heatwaves_manual/all_temperature_data_clean.rds"))
m <- read_rds(paste0(getwd(), "/calculated/all_mortality.rds"))
#get the 300 counties with the highest populations
m_pops <- m %>% group_by(fips) %>% summarise(population = mean(as.numeric(population_est))) %>% arrange(desc(population))
m_pops <- m_pops[1:300,]
m <- m %>% dplyr::filter(fips %in% m_pops$fips)
pdf(paste0("heatwaves_manual/visuals/regressions", Sys.Date(), ".pdf"))
##Finalize datasets for regressions & run
####################
## Quick function that takes data and plots all the variations we'd want
plot_data <- function(data, plot_title) {
plot(c(0, 1), c(0, 1), ann = F, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n',
main = title)
text(x = 0.5, y = 0.5, paste(timestamp()),
cex = 1.5, col = "black")
par(mfcol = c(2,2))
print(plot_title)
model <- fe_model(data, level = 2)
boots <- bootstrap_data(data, short=T, level=2)
plot_regs(data, boots, plot_title, level = 2, xlabel = "#Days @ or Above percentile", model=model)
data$deaths <- log(data$deaths)
model <- fe_model(data, level = 2)
boots <- bootstrap_data(data, short=T, level=2)
plot_regs(data, boots, plot_title, level = 2,xlabel = "#Days @ or Above percentile", ylabel = "Log Mortality", model = model)
}
head(t)
m
head(m)
substr(m$county[1:10], -2)
str_sub(m$county[1:10], -2)
m$state <- str_sub(m$county, -2)
head(m)
unique(m$state)
t
head(t)
ifelse(dir.exists("~/Box Sync/heatwave_covid"),
setwd("~/Box Sync/heatwave_covid"),
setwd("/oak/stanford/groups/omramom/group_members/aminaly/heatwave_covid"))
source("./regression_functions.R")
library(dplyr)
library(lfe)
library(ggplot2)
library(dotwhisker)
library(tidyverse)
library(lubridate)
library(reshape2)
library(stringr)
##Read in datasets
t <- read_rds(paste0(getwd(), "/heatwaves_manual/all_temperature_data_clean.rds"))
m <- read_rds(paste0(getwd(), "/calculated/all_mortality.rds"))
#get the 300 counties with the highest populations
m_pops <- m %>% group_by(fips) %>% summarise(population = mean(as.numeric(population_est))) %>% arrange(desc(population))
m_pops <- m_pops[1:300,]
m <- m %>% dplyr::filter(fips %in% m_pops$fips)
m$state <- str_sub(m$county, -2)
####################
## Quick function that takes data and plots all the variations we'd want
plot_data <- function(data, plot_title) {
plot(c(0, 1), c(0, 1), ann = F, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n',
main = title)
text(x = 0.5, y = 0.5, paste(timestamp()),
cex = 1.5, col = "black")
par(mfcol = c(2,2))
print(plot_title)
model <- fe_model(data, level = 2)
boots <- bootstrap_data(data, short=T, level=2)
plot_regs(data, boots, plot_title, level = 2, xlabel = "#Days @ or Above percentile", model=model)
data$deaths <- log(data$deaths)
model <- fe_model(data, level = 2)
boots <- bootstrap_data(data, short=T, level=2)
plot_regs(data, boots, plot_title, level = 2,xlabel = "#Days @ or Above percentile", ylabel = "Log Mortality", model = model)
}
####################
##For this set of regressions, we're going to do per capita deaths, regular and log mortality,
## and only summmer months
## Recalculate z-scores for just the summer months and add in percentile value
t_zs <- t %>% group_by(fips, year) %>%
mutate(z_score_high = (mean_high - mean(mean_high)) / sd(mean_high)) %>%
mutate(z_score_low = (mean_low - mean(mean_low)) / sd(mean_low)) %>%
mutate(p_high = pnorm(z_score_high)) %>%
mutate(p_low = pnorm(z_score_low)) %>%
ungroup
## Per Capita Deaths, summer months, num days where avg high temp in county is above 90th percentile
t_high <- t_zs %>% group_by(county, fips, month, year, monthyear) %>%
summarize(num_90 = sum(p_high >= 0.9))
data <- left_join(m, t_high, by = c("fips", "month", "year"))
data <- data %>%
group_by(fips, measure = num_90, monthyear, county = county.x, income_group, population_est, state, year) %>%
summarise(deaths = sum(deaths, na.rm = T)) %>%
dplyr::filter(is.finite(measure)) %>%
mutate(deaths = (deaths/as.numeric(population_est))*100000)
data <- na.omit(data)
plot_title <- "Deaths per 100K + #Days high >90P"
plot_data(data, plot_title)
##------ Mon Aug 10 22:06:05 2020 ------##
####Functions####
# Dta is the data
# Data must have the following columns: deaths, measure (temp), fips (county id), monthyear (pasted together)
fe_model <- function(dta, level, interact=F) {
dta <- na.omit(dta, cols=c("measure", "deaths"))
dta$stateyear <- paste0(dta$state, dta$year)
# if(interact) {
#   if (level == 1) {
#     mod <- felm(deaths ~ measure + measure:income_group | fips + monthyear, data=dta)
#   } else if (level == "log") {
#     mod <- felm(deaths ~ log(measure) + log(measure):income_group | fips + monthyear, data=dta )
#   } else if (level > 1) {
#     mod <- felm(deaths ~ poly(measure,level,raw=T) + measure:income_group | fips + monthyear, data=dta)
#   }
# } else {
if (level == 1) {
mod <- felm(deaths ~ measure | fips + monthyear, data=dta)
} else if (level == "log") {
mod <- felm(deaths ~ log(measure) | fips + monthyear, data=dta )
} else if (level > 1) {
mod <- felm(deaths ~ poly(measure,level,raw=T) +
as.factor(state)*year | fips + monthyear | 0 | fips + stateyear, data=dta)
}
#}
return(mod)
}
debug(fe_model)
plot_data(data, plot_title)
##------ Mon Aug 10 22:06:32 2020 ------##
head(dta)
head(dta)
undebug(fe_model)
debug(bootstrap_data)
plot_data(data, plot_title)
##------ Mon Aug 10 22:07:51 2020 ------##
coef
head(data)
data$stateyear <- paste0(data$state, data$year)
plot_title <- "Deaths per 100K + #Days high >90P"
plot_data(data, plot_title)
##------ Tue Aug 11 09:53:34 2020 ------##
v
plot_data(data, plot_title)
##------ Tue Aug 11 09:54:08 2020 ------##
coef
head(newdata)
max(newdata$measure)
model
coef(model)
coef(model[1:level])
coef(model[1:level,])
model[1:@]
model[1:2]
model[,1:2]
model[1:2,]
head(model)
coef(model)[1:2]
coef(model)[1:level]
#Function to use in order to get a 95% confidence interval for our regression
#Bootstraps the data and essentially resamples and runs the same regression on subset of the data a bunch of times
#Level refers to the type of regression we are running. 1 = linear 2 = quadratic "log" = log of course
#returns a list of coefficients that can be used for plotting
bootstrap_data <- function(data, short=T, level, interact=F, name = "") {
num <- ifelse(short, 100, 1000)
ll = dim(data)[1]
# if(interact) {
#   coef <- matrix(nrow=num, ncol=(ifelse(level=="log", 1, level) + 1))
# } else {
#
# }
coef <- matrix(nrow=num, ncol=ifelse(level=="log", 1, level))
i <- 1
while (i <= num)  {
#sample the original data and pull subset of rows
samp <- sample(1:ll,size=ll,replace=T)
newdata = data[samp,]
#estimate our regression y = b1*T + err
model <- fe_model(newdata, level, interact)
#extract the coefficient estimates of b1 and b2 and store them in the matrix we made above
if(level == "log") {coef[i,] <- coef(model)[1]} else {coef[i,] <- coef(model)[1:level]}
print(i)  #print this out so you can watch progress
i <- i+1
}
#save it out for the next run if name was provided
returnlist <- list(coef)
return(returnlist)
}
plot_data(data, plot_title)
##------ Tue Aug 11 09:58:04 2020 ------##
#Function to use in order to get a 95% confidence interval for our regression
#Bootstraps the data and essentially resamples and runs the same regression on subset of the data a bunch of times
#Level refers to the type of regression we are running. 1 = linear 2 = quadratic "log" = log of course
#returns a list of coefficients that can be used for plotting
bootstrap_data <- function(data, short=T, level, interact=F, name = "") {
num <- ifelse(short, 100, 1000)
ll = dim(data)[1]
# if(interact) {
#   coef <- matrix(nrow=num, ncol=(ifelse(level=="log", 1, level) + 1))
# } else {
#
# }
coef <- matrix(nrow=num, ncol=ifelse(level=="log", 1, level))
i <- 1
while (i <= num)  {
#sample the original data and pull subset of rows
samp <- sample(1:ll,size=ll,replace=T)
newdata = data[samp,]
#estimate our regression y = b1*T + err
model <- fe_model(newdata, level, interact)
#extract the coefficient estimates of b1 and b2 and store them in the matrix we made above
if(level == "log") {coef[i,] <- coef(model)[1]} else {coef[i,] <- coef(model)[1:level]}
print(i)  #print this out so you can watch progress
i <- i+1
}
#save it out for the next run if name was provided
returnlist <- list(coef)
return(returnlist)
}
## Per Capita Deaths, summer months, num days where avg high temp in county is above 90th percentile
t_low <- t_zs %>% group_by(county, fips, month, year, monthyear) %>%
summarize(num_90 = sum(p_low >= 0.9))
plot_data(data, plot_title)
##------ Tue Aug 11 09:59:27 2020 ------##
